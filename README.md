# DLEX01---Feed-Forward-Neural-Network
The goal of this assignment is to implement the core components of a feed-forward neural network, including layers, activation functions, loss functions, and optimization algorithms. The implementation is modular, making it easy to extend or modify individual components.

Check Description for Problem Statement

Help yourselves with whatever you want
Download submission.zip for al files and to see entire Heirarchy of python files

# File Structure
.
├── Base.py                # Base class for layers
├── FullyConnected.py      # Implementation of fully connected (dense) layer
├── Helpers.py             # Utility functions for the network
├── Loss.py                # Loss function implementations (e.g., MSE, Cross-Entropy)
├── NeuralNetwork.py       # Main neural network class
├── NeuralNetworkTests.py  # Unit tests for the neural network
├── Optimizers.py          # Optimizer implementations (e.g., SGD)
├── ReLU.py                # ReLU activation function
├── SoftMax.py             # Softmax activation function
├── Description.pdf        # Assignment description and problem statement
├── submission.zip         # Zipped archive of all files for submission
└── README.md              # This file

# Project Details
Layers: Modular implementation of fully connected layers, ReLU, and Softmax.
Loss Functions: Includes common loss functions for classification and regression.
Optimizers: Basic optimizers such as Stochastic Gradient Descent (SGD).
Testing: Unit tests are provided to verify the correctness of each component.
For a detailed problem statement and assignment requirements, refer to Description.pdf

# License
This project is for educational purposes as part of a university assignment. Please do not redistribute without permission
